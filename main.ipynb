{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f9a06e9-6bb2-4d6e-9c03-96c612a944be",
   "metadata": {},
   "source": [
    "# A Keras 'Bare-Bones' Implementation of ResNet-34\n",
    "\n",
    "First we'll create the residual unit, made up of two convolutional layers (no pooling layers), using Batch Normalization, ReLU activations, a 3x3 kernel, and preserved spatial dimensions (using a stride of 1, padding \"same\"; zero padding added to input so that output has the same spatial dimensions).\n",
    "\n",
    "> Note: The bias term shifts the inputs passed to ReLU, ensuring activation even in the absense of strong input signals. It can be helpful to think of this as the general \"brightness\" of the filter. However, with a BatchNormalization layer sitting before the activation function, the output is normalized using separate trainable parameters (gamma, beta). This leaves the offset achieved by the bias term redundant, so we can specify we don't want to use bias terms when constructing the conv layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "408b14f0-1c95-4e5e-ac79-ce7eef336b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from functools import partial\n",
    "\n",
    "DefaultConv2D = partial(\n",
    "    tf.keras.layers.Conv2D, \n",
    "    kernel_size=3, strides=1, padding=\"same\", kernel_initializer=\"he_normal\", use_bias=False)\n",
    "\n",
    "class ResUnit(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.activation = tf.keras.layers.Activation(activation)\n",
    "        self.main_layers = [\n",
    "            DefaultConv2D(filters, strides=strides),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            self.activation,\n",
    "            DefaultConv2D(filters),\n",
    "            tf.keras.layers.BatchNormalization()\n",
    "        ]\n",
    "        self.skip_layers = []\n",
    "        if strides > 1:\n",
    "            self.skip_layers = [\n",
    "                DefaultConv2D(filters, kernel_size=1, strides=strides),\n",
    "                tf.keras.layers.BatchNormalization()\n",
    "            ]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        main_output = inputs\n",
    "        for layer in self.main_layers:\n",
    "            main_output = layer(main_output)\n",
    "        skip_output = inputs\n",
    "        for layer in self.skip_layers:\n",
    "            skip_output = layer(skip_output)\n",
    "        return self.activation(main_output + skip_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f114416-b254-48f5-924d-e6ea6bae82df",
   "metadata": {},
   "source": [
    "When the number of feature maps is doubled and the spatial dimension is halved (using a convolutional layer with a stride of 2), the input and output shapes of the residual unit differ. To enable concatenation of the input and output, the skip connection should pass through a 1x1 convolutional layer with the same stride and number of feature maps as the main convolutional layer. The skip connections will pass through the `skip_layers`.\n",
    "\n",
    "![resnet-block.svg](./resnet-block.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ba91cbe-6484-4425-8cf2-a9a077692ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    DefaultConv2D(64, kernel_size=7, strides=2, input_shape=[224, 224, 3]),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation(\"relu\"),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"same\"),\n",
    "])\n",
    "\n",
    "# count of filters for each stage in ResNet-34\n",
    "filter_configuration = [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3\n",
    "previous_filters = 64\n",
    "\n",
    "for filters in filter_configuration:\n",
    "    # if number of filters has changed, update the stride\n",
    "    strides = 1 if filters == previous_filters else 2\n",
    "    model.add(ResUnit(filters, strides=strides))\n",
    "    previous_filters = filters\n",
    "\n",
    "model.add(tf.keras.layers.GlobalAvgPool2D())\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02db9af4-f81c-4df9-854e-800266d5dea8",
   "metadata": {},
   "source": [
    "As can be seen, the architecture of a ResNet-34 includes:\n",
    "- 3 RUs with 43 feature maps\n",
    "- 4 RUs with 128 feature maps\n",
    "- 6 RUs with 256 feature maps\n",
    "- 3 RUs with 512 feature maps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
